
2024-06-06T07:39:31.170754
================================ System Message ================================

You will get instructions for code to write.
You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.
Think step by step and reason yourself to the correct decisions to make sure we get it right.
First lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.

You will output the content of each file necessary to achieve the goal, including ALL code.
Represent files like so:

FILENAME
```
CODE
```

The following tokens must be replaced like so:
FILENAME is the lowercase combined path and file name including the file extension
CODE is the code in the file

Example representation of a file:

src/hello_world.py
```
print("Hello World")
```

Do not comment on what every file does. Please note that the code should be fully functional. No placeholders.


You will start with the "entrypoint" file, then go to the ones that are imported by that file, and so on.
Please note that the code should be fully functional. No placeholders.

Follow a language and framework appropriate best practice file naming convention.
Make sure that files contain all imports, types etc.  The code should be fully functional. Make sure that code in different files are compatible with each other.
Ensure to implement all code, if you are unsure, write a plausible implementation.
Include module dependency or package manager dependency definition file.
Before you finish, double check that all parts of the architecture is present in the files.

When you are done, write finish with "this concludes a fully working implementation".

Useful to know:
Almost always put different classes in different files.
Always use the programming language the user asks for.
For Python, you always create an appropriate requirements.txt file.
For NodeJS, you always create an appropriate package.json file.
Always add a comment briefly describing the purpose of the function definition.
Add comments explaining very complex bits of logic.
Always follow the best practices for the requested languages for folder/file structure and how to package the project.


Python toolbelt preferences:
- pytest
- dataclasses


================================ Human Message =================================

Request: I need a python code that lists all json files in a specific path in azure files share and then reads the latest file based on regex match and a date in the file name, for example I have 4 files under the same path : Refunds_20240606.json / Refunds_20240605.json / Ref_20240607.json / Refunds_rejections_20240606.json, the code should read only one file Refunds_20240606.json

================================== Ai Message ==================================

To achieve the desired functionality, we need to create a Python project that interacts with Azure File Share, lists JSON files, and reads the latest file based on a regex match and a date in the file name. We'll use the `azure-storage-file-share` library to interact with Azure File Share and `re` for regex operations.

Here is the step-by-step breakdown of the necessary components:

1. **AzureFileShareClient**: A class to handle interactions with Azure File Share.
2. **FileProcessor**: A class to process the files, including listing and reading the latest file based on regex and date.
3. **main.py**: The entry point of the application.
4. **requirements.txt**: To list the dependencies.

Let's start by defining the core classes and their methods:

- **AzureFileShareClient**:
  - `__init__`: Initialize the client with connection details.
  - `list_files`: List all files in a specific path.

- **FileProcessor**:
  - `__init__`: Initialize with an instance of AzureFileShareClient.
  - `get_latest_file`: Get the latest file based on regex match and date in the file name.
  - `read_file`: Read the content of the specified file.

Now, let's implement the code step by step.

### requirements.txt
```
azure-storage-file-share==12.5.0
```

### src/azure_file_share_client.py
```
from azure.storage.fileshare import ShareServiceClient
from typing import List

class AzureFileShareClient:
    def __init__(self, connection_string: str, share_name: str):
        self.service_client = ShareServiceClient.from_connection_string(conn_str=connection_string)
        self.share_client = self.service_client.get_share_client(share_name)

    def list_files(self, directory_name: str) -> List[str]:
        directory_client = self.share_client.get_directory_client(directory_name)
        file_list = []
        for item in directory_client.list_directories_and_files():
            if not item['is_directory']:
                file_list.append(item['name'])
        return file_list
```

### src/file_processor.py
```
import re
from datetime import datetime
from azure_file_share_client import AzureFileShareClient

class FileProcessor:
    def __init__(self, azure_client: AzureFileShareClient):
        self.azure_client = azure_client

    def get_latest_file(self, directory_name: str, regex_pattern: str) -> str:
        files = self.azure_client.list_files(directory_name)
        matched_files = [f for f in files if re.match(regex_pattern, f)]
        
        if not matched_files:
            return None
        
        # Extract date from file name and sort by date
        def extract_date(file_name: str) -> datetime:
            match = re.search(r'\d{8}', file_name)
            if match:
                return datetime.strptime(match.group(), '%Y%m%d')
            return datetime.min
        
        matched_files.sort(key=extract_date, reverse=True)
        return matched_files[0]

    def read_file(self, directory_name: str, file_name: str) -> str:
        file_client = self.azure_client.share_client.get_file_client(f"{directory_name}/{file_name}")
        download = file_client.download_file()
        return download.readall().decode('utf-8')
```

### src/main.py
```
import os
from azure_file_share_client import AzureFileShareClient
from file_processor import FileProcessor

def main():
    connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')
    share_name = os.getenv('AZURE_SHARE_NAME')
    directory_name = os.getenv('AZURE_DIRECTORY_NAME')
    regex_pattern = r'^Refunds_\d{8}\.json$'

    azure_client = AzureFileShareClient(connection_string, share_name)
    file_processor = FileProcessor(azure_client)

    latest_file = file_processor.get_latest_file(directory_name, regex_pattern)
    if latest_file:
        content = file_processor.read_file(directory_name, latest_file)
        print(f"Latest file: {latest_file}")
        print(f"Content: {content}")
    else:
        print("No matching files found.")

if __name__ == "__main__":
    main()
```

### .env (for environment variables)
```
AZURE_STORAGE_CONNECTION_STRING=your_connection_string_here
AZURE_SHARE_NAME=your_share_name_here
AZURE_DIRECTORY_NAME=your_directory_name_here
```

### Directory Structure
```
project_root/
│
├── src/
│   ├── azure_file_share_client.py
│   ├── file_processor.py
│   └── main.py
├── .env
└── requirements.txt
```

This concludes a fully working implementation.

2024-06-06T07:43:58.830046
================================ System Message ================================

You will get instructions for code to write.
You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.
Think step by step and reason yourself to the correct decisions to make sure we get it right.
First lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.

You will output the content of each file necessary to achieve the goal, including ALL code.
Represent files like so:

FILENAME
```
CODE
```

The following tokens must be replaced like so:
FILENAME is the lowercase combined path and file name including the file extension
CODE is the code in the file

Example representation of a file:

src/hello_world.py
```
print("Hello World")
```

Do not comment on what every file does. Please note that the code should be fully functional. No placeholders.


You will start with the "entrypoint" file, then go to the ones that are imported by that file, and so on.
Please note that the code should be fully functional. No placeholders.

Follow a language and framework appropriate best practice file naming convention.
Make sure that files contain all imports, types etc.  The code should be fully functional. Make sure that code in different files are compatible with each other.
Ensure to implement all code, if you are unsure, write a plausible implementation.
Include module dependency or package manager dependency definition file.
Before you finish, double check that all parts of the architecture is present in the files.

When you are done, write finish with "this concludes a fully working implementation".

Useful to know:
Almost always put different classes in different files.
Always use the programming language the user asks for.
For Python, you always create an appropriate requirements.txt file.
For NodeJS, you always create an appropriate package.json file.
Always add a comment briefly describing the purpose of the function definition.
Add comments explaining very complex bits of logic.
Always follow the best practices for the requested languages for folder/file structure and how to package the project.


Python toolbelt preferences:
- pytest
- dataclasses


================================ Human Message =================================

Request: I need an airflow task as python operator that lists all json files in a specific path in azure files share and then reads the latest file based on regex match and a date in the file name, for example I have 4 files under the same path : Refunds_20240606.json / Refunds_20240605.json / Ref_20240607.json / Refunds_rejections_20240606.json, the code should read only one file Refunds_20240606.json

================================== Ai Message ==================================

Sure, let's break down the task and implement it step by step. We'll create an Airflow DAG that uses a PythonOperator to list all JSON files in a specific path in an Azure File Share and then reads the latest file based on a regex match and a date in the file name.

### Core Classes, Functions, and Methods
1. **AzureFileShareHook**: A custom hook to interact with Azure File Share.
2. **list_json_files**: A function to list all JSON files in a specific path.
3. **get_latest_file**: A function to get the latest file based on regex match and date in the file name.
4. **read_file**: A function to read the content of the selected file.
5. **main_dag**: The main DAG definition.

### File Structure
1. `dags/main_dag.py`: The entrypoint file for the Airflow DAG.
2. `plugins/hooks/azure_file_share_hook.py`: Custom hook to interact with Azure File Share.
3. `plugins/utils/file_utils.py`: Utility functions for file operations.
4. `requirements.txt`: Dependencies for the project.

### Implementation

#### requirements.txt
```
apache-airflow==2.3.0
azure-storage-file-share==12.4.1
```

#### dags/main_dag.py
```python
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta
from plugins.utils.file_utils import list_json_files, get_latest_file, read_file

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

def list_and_read_latest_file(**kwargs):
    path = kwargs['path']
    files = list_json_files(path)
    latest_file = get_latest_file(files)
    content = read_file(latest_file)
    print(content)

with DAG(
    'azure_file_share_dag',
    default_args=default_args,
    description='A simple DAG to list and read the latest JSON file from Azure File Share',
    schedule_interval=timedelta(days=1),
    start_date=datetime(2023, 1, 1),
    catchup=False,
) as dag:

    task = PythonOperator(
        task_id='list_and_read_latest_file',
        python_callable=list_and_read_latest_file,
        op_kwargs={'path': 'your/azure/file/share/path'},
    )

    task
```

#### plugins/hooks/azure_file_share_hook.py
```python
from azure.storage.fileshare import ShareServiceClient
import os

class AzureFileShareHook:
    def __init__(self, connection_string):
        self.connection_string = connection_string
        self.service_client = ShareServiceClient.from_connection_string(conn_str=connection_string)

    def list_files(self, share_name, directory_name):
        share_client = self.service_client.get_share_client(share_name)
        directory_client = share_client.get_directory_client(directory_name)
        return [file.name for file in directory_client.list_directories_and_files()]

    def read_file(self, share_name, directory_name, file_name):
        share_client = self.service_client.get_share_client(share_name)
        file_client = share_client.get_file_client(os.path.join(directory_name, file_name))
        download = file_client.download_file()
        return download.readall().decode('utf-8')
```

#### plugins/utils/file_utils.py
```python
import re
from datetime import datetime
from plugins.hooks.azure_file_share_hook import AzureFileShareHook

def list_json_files(path):
    connection_string = 'your_connection_string'
    share_name = 'your_share_name'
    directory_name = path
    hook = AzureFileShareHook(connection_string)
    files = hook.list_files(share_name, directory_name)
    return [file for file in files if file.endswith('.json')]

def get_latest_file(files):
    regex = re.compile(r'Refunds_\d{8}\.json')
    matched_files = [file for file in files if regex.match(file)]
    if not matched_files:
        return None
    matched_files.sort(key=lambda x: datetime.strptime(x.split('_')[1].split('.')[0], '%Y%m%d'), reverse=True)
    return matched_files[0]

def read_file(file_name):
    connection_string = 'your_connection_string'
    share_name = 'your_share_name'
    directory_name = 'your/azure/file/share/path'
    hook = AzureFileShareHook(connection_string)
    return hook.read_file(share_name, directory_name, file_name)
```

This concludes a fully working implementation.
